# DO NOT EDIT THIS FILE EXCEPT AS //depot/google3/tools/google3__init__.py
# Once you edit there, make sure you copy it to //depot/google3/__init__.py
# and submit both files in the same change.

"""This is the root of the google3 tree.

Code in here is built by the Google3 build system.
"""

# Copyright 2006 Google Inc. All Rights Reserved.
#
# This file sets up import mechanisms for all Google3 programs.  Every
# Google3 program should import this file.  If the program uses
# third-party modules such as MySQLdb, it should import this file
# before importing any third-party code.
#
# The public API provided by this module:
#
#   basedir: The directory containing this file.
#
# Implementation notes:
#
# This file must be source compatible with both Python 2 and 3.
# This module makes use of 'meta-import hooks', as described in PEP 302.

import os
import sys
import warnings

########################################################################
# Support "union" imports for thin clients, that merge together
# several directory trees into a single "virtual" directory tree for
# Python imports.
########################################################################


def _SetupPath(old_path, this_dir):
  """Setup package import path for Google3.

  old_path: List of directories.
  this_dir: Directory that this package is loaded from.

  Allow the google3 package to import subpackages and modules from
  several different directory trees: The standard perforce client, the
  READONLY directory maintained by gcheckout, and /home/build.

  TODO(dgreiman): /home/build is a bit of a can of worms: Sometimes
  you want to take things from /home/build and sometimes you don't.
  I.e. in a par file you don't.  In a release branch you don't.  On a
  production machine you don't.  Eventually we want to give people a
  way to conditionally add /home/build to their path, or not.  For
  now, we try to prevent the problem from getting any bigger without
  breaking the existing programs that depend on it.  For this reason,
  we don't take third-party modules from /home/build and we don't do
  directory merging with /home/build, but we do allow importing
  modules directly under google3 from /home/build.

  TODO(dgreiman): Add bin/ and genfiles/ once the build tree layout is
  rearranged to allow this to work.  Basically remove
  directory-doubling for .py generated files.

  This code sets the top-level path, and relies on
  Google3MetaImportHook to propagate the path to subpackages.

  Returns a list of three things:

  The first is the new package path, consisting of the old package
  path reordered and with extra directories inserted.

  The second is a subset of the first, consisting of all the google3
  directories that we might want to take third-party modules from.

  The third is a boolean saying whether a READONLY directory was
  found.  If true, the 'directory merging' functionality will be
  activated.  Note that this will never be true if running from a .par
  file, since 'client_root' will be '/somedir/somefile.par' and thus
  '/somedir/somefile.par/READONLY' will not be a directory.

  """

  # If running in a stateless client, take packages from
  # <clientroot>/READONLY/google3/.  If already in READONLY dir, take
  # packages from <clientroot>/google3/.  The read-write client should
  # always be first in precedence.
  this_dir = os.path.abspath(this_dir)
  parent_dir = os.path.dirname(this_dir)

  # If this program started inside the readonly tree, the path may
  # either be the "short" symlink
  # /home/<user>/<p4client>/READONLY/google3, or the actual "long"
  # directory name
  # /usr/local/google/home/<usr>/<p4client>/READONLY/stateless-client/google3
  # This code must match the paths used in
  # google3/tools/perforce/stateless_sync.py
  if os.path.basename(parent_dir) == 'READONLY':  # "short"
    client_root = os.path.dirname(parent_dir)
    readwrite_dir = os.path.join(client_root, 'google3')
    readonly_dir = os.path.join(client_root, 'READONLY', 'google3')
    have_readonly_dir = 1
  elif (parent_dir.endswith('/READONLY/stateless-client') and
        parent_dir.startswith('/usr/local/google/')):  # "long"
    # We make sure client_root starts with /
    client_root = parent_dir[len('/usr/local/google'):
                             -len('/READONLY/stateless-client')]
    readwrite_dir = os.path.join(client_root, 'google3')
    # Note that readonly and readwrite have different parents
    readonly_dir = os.path.join(parent_dir, 'google3')
    have_readonly_dir = 1
  else:
    client_root = parent_dir
    readwrite_dir = os.path.join(client_root, 'google3')
    readonly_dir = os.path.join(client_root, 'READONLY', 'google3')
    have_readonly_dir = os.path.isdir(readonly_dir)

  # The readwrite_dir may actually be in a zipfile, so we don't check
  # for existence.  We do however check the readonly dir, since it
  # will always be a real directory.
  google3_path = [readwrite_dir]
  if have_readonly_dir:
    google3_path.append(readonly_dir)

  package_path = google3_path[:]

  # Fall back to /home/build.
  #
  # We test for the existence of os.R_OK because the jython
  # implementation of os doesn't have it.
  if (not os.environ.get('GOOGLE3_NO_HOME_BUILD') and
      not _RunningProgramIsAParFile()):
    if not hasattr(os, 'R_OK') or os.access('/home/build/google3/.', os.R_OK):
      package_path.append('/home/build/google3')
    else:
      package_path.append('/home/build/nonconf/google3')

  # The existing path shouldn't have anything else, but just in case,
  # keep unexpected items.
  for pathdir in old_path:
    if pathdir not in package_path:
      package_path.append(pathdir)

  return (package_path, google3_path, have_readonly_dir)


#_A list of directories that should not be propagated to
# subpackages.  This is basically a hack while we figure out a good
# solution to /home/build.

_NO_INHERIT = [
    '/home/build/google3',
    '/home/build/nonconf/google3',
    ]


def _FixupParentPathByName(module_name):
  """Given a module name, find its parent package, and fix that package's path.

  module_name: Fully-qualified module name

  """

  # Find parent and grandparent package.
  lastdot = module_name.rfind('.')
  if lastdot == -1:
    return
  second_lastdot = module_name.rfind('.', 0, lastdot)
  if second_lastdot == -1:
    return
  parent_name = module_name[:lastdot]
  parent = sys.modules.get(parent_name)
  grandparent_name = module_name[:second_lastdot]
  grandparent = sys.modules.get(grandparent_name)

  if parent and grandparent:
    _MaybeInheritPath(parent_name, parent, grandparent)


def _FixupPackagePathByObject(package):
  """Given a package object, fixup its path if necessary.

  package: Module object

  A no-op if called on a non-package module.

  """

  # Is it even a package?
  if not hasattr(package, '__path__'):
    return

  package_name = getattr(package, '__name__', None)
  # Some special modules don't have names, ignore them
  if not package_name:
    return

  # Find package's parent if any
  lastdot = package_name.rfind('.')
  if lastdot == -1:
    return
  package_parent_name = package_name[:lastdot]
  package_parent = sys.modules.get(package_parent_name)

  if package_parent:
    _MaybeInheritPath(package_name, package, package_parent)


def _MaybeInheritPath(package_name, package, package_parent):
  """Given a package, fixup its path if necessary.

  package_name: Fully-qualified module name
  package, package_parent_name: Module objects
  """

  # Already did this one?
  if getattr(package, '_g_inherit_processed__', 0):
    return

  # Package has disabled inheritance?
  if not getattr(package, '_g_inherit_path__', 1):
    return

  # Package's parent hasn't enabled inheritance?
  if not getattr(package_parent, '_g_inherit_path__', 0):
    return

  # Propagate path down
  _InheritPath(package_name, package, package_parent)


def _InheritPath(package_name, package, package_parent):
  """Compute a path for a package, based on the path of its parent.

  If package is named spam.eggs, then for each entry D in
  package_parent's path, add D/eggs to package's path.

  package_name: Fully qualified package name
  package, package_parent: Module objects

  """

  basename = package_name.split('.')[-1]
  assert basename, 'Contact build-help@google.com'

  orig_package_path = getattr(package, '__path__', [])

  # Pull down each path item from parent
  new_path = []
  for pathdir in getattr(package_parent, '__path__', []):
    if pathdir not in _NO_INHERIT:
      newdir = os.path.join(pathdir, basename)

      # To save I/O, we only add directories that 1) actually exist,
      # or 2) were in the original path.  Condition #2 is present to
      # accommodate import hooks that might put arbitrary strings on
      # the __path__.
      if newdir in orig_package_path or os.path.isdir(newdir):
        new_path.append(newdir)

  # If path had pre-existing entries, keep them.
  for pathdir in orig_package_path:
    if pathdir not in new_path:
      new_path.append(pathdir)

  # We mutate the path in-place since we might be in the process of
  # using it to import something.
  package.__path__[:] = new_path
  package._g_inherit_path__ = 1
  package._g_inherit_processed__ = 1


class _Python23MergeImportsHook:
  """Propagate package search path to all subpackages of Google3.

  This class is a meta-import hook, as defined by Python 2.3 and
  above.  Instead of actually importing anything, it works like a
  pre-import hook to fix up the __path__ in a package object that has
  already been imported.

  Consider packages A, A.B, and A.B.C.  A's __path__ contains a list
  of directories.  We want A.B's __path__ to be set to the same list
  of directories, except with '/B' appended to each one.  We could
  update A.B's __path__ when A.B is first imported, but that is
  difficult to implement.  Instead, we allow A.B's path to be
  incorrect until A.B.C is imported.  When A.B.C is imported, this
  hook runs, looks at A's __path__, and copies it with modifications
  to A.B's __path__.  The updated __path__ is then used by the normal
  import mechanism to find A.B.C.

  """

  def find_module(self, module_name, unused_path=None):
    """Called by standard Python import mechanism.

    module_name: Fully-qualified module name
    unused: List of directories to search, from parent package.

    We use this as a signal that a module is about to be imported, and
    fixup its parent's path if necessary.

    We then return a failure notification (via 'return None'), so that
    the normal import process continues.

    """

    _FixupParentPathByName(module_name)
    return None  # import.c interprets this as failure to find


_merge_imports_hook_installed = 0


def _SetupMergeImportsHook(have_readonly_dir):
  """Enable hook to merge directory trees for imports.

  have_readonly_dir: 1 if [p4 client]/READONLY exists
  """

  # Don't load the hook twice
  global _merge_imports_hook_installed
  if _merge_imports_hook_installed:
    return

  # If don't have readonly dir, then this merge functionality isn't
  # (currently) needed, so don't enable it.  Also provide environment
  # variable to disable functionality if something goes haywire.
  if not have_readonly_dir or os.environ.get('GOOGLE3_DISABLE_MERGE_IMPORTS'):
    return

  _merge_imports_hook_installed = 1

  meta_path = getattr(sys, 'meta_path', [])
  meta_path.append(_Python23MergeImportsHook())


def _RunningProgramIsAParFile():
  """Returns whether or not sys.argv[0] (the running program) is a par file.

     Sadly, copied from google3/pyglib/parinfo.py to avoid dependency probs.
  """
  loader = globals().get('__loader__', None)
  if not loader or not hasattr(loader, '__module__'):
    return 0
  module = sys.modules[loader.__module__]
  return hasattr(module, 'AUTOPAR_VERSION')


########################################################################
# Support third-party imports using standard names like mx
# instead of google3.third_party.python.mx
########################################################################


def _SetupThirdParty(sys_path, google3_path):
  """Setup import path to code in google3/third_party/py.

  sys_path: Original sys.path
  google3_path: Google3 dirs being added to sys.path

  Returns nothing, modifies sys_path in place.
  """

  third_party_path = [os.path.join(d, 'third_party', 'py')
                      for d in google3_path]

  # Add third_party dirs to import path
  found_site_packages = idx = 0
  # Insert immediately before the first site-package dir
  for idx in range(len(sys_path)):
    dirname = sys_path[idx]
    if dirname.find('site-packages') != -1:
      found_site_packages = 1
      break

  if found_site_packages:
    sys_path[idx:idx] = third_party_path
  else:
    # Append to end if no site-packages found
    sys_path.extend(third_party_path)

  # Check for import order mistakes
  path_hooks = getattr(sys, 'path_hooks', [])
  _CheckThirdParty(third_party_path, path_hooks, sys.modules)

  return None


def _CheckThirdParty(third_party_path, path_hooks, sys_modules):
  """Check for erroneous imports from site-packages directory.

  third_party_path: List of path entries.  Each is an absolute
                    directory name, but may be a pseudo-path formed by
                    concatenating a .par filename with a subdir.
                    E.g. '/home/zog/src1/google3/third_party/py' or
                    '/root/myprog.par/google3/third_party/py'.

  For each top-level module or package that was imported from Python's
  site-package directory, but should have been imported from
  [client]/google3/third_party/py instead, issue a warning message.

  We try to determine this with a minimum of I/O, and without fully
  reimplementing import().  So we use heuristics: We only look at top
  level modules or packages (no dots), and we assume that every file
  or directory in google3/third_party/py is a module or package name.
  Since we control google3/third_party/py, this is generally safe.

  Returns a list of problematic modules
  """

  # Examine third-party dirs.
  path_data = _ExaminePath(third_party_path, path_hooks)

  # Iterate over all top-level modules loaded from site-packages.
  problems = []
  for module_name, module in sys_modules.items():
    if module_name.find('.') == -1:
      # Is module from site-packages?
      fn = getattr(module, '__file__', None)
      if fn and fn.find('site-packages') != -1:
        # Look for same-named module in third_party
        third_party_fn = _FindInPath(module_name, path_data)
        if third_party_fn:
          msg = ('%s is deprecated, use %s instead.  To fix this, move '
                 '"import google3" or "from google3... import ..." before '
                 '"import %s" in your main source file.' % (
                     fn, third_party_fn, module_name))
          warnings.warn(msg, DeprecationWarning, stacklevel=2)
          problems.append((fn, third_party_fn, module_name))

  return problems


def _ExaminePath(dirs, path_hooks):
  """Determine the type and contents of a list of import path entries.

  dirs:  List of path entries as above.
  path_hooks: Contents of sys.path_hooks

  We categorize each directory as 1) real directory or 2) zipfile.
  There is no usable Python-level API to access the import internals,
  so we have to reimplement sys.path_hooks
  processing. [imp.find_module() doesn't work because it wasn't
  updated when new-style import hooks were added to Python 2.3]

  Returns a list of (path, [dir contents if real dir], loader if zipfile)
  """

  path_data = []
  for dirname in dirs:
    # Get possible modules and packages in this dir
    files = []
    try:
      files = []
      for f in os.listdir(dirname):
        # Look for no extension (i.e. directory) or a .py* extension.
        # Note that some interpreters use things like foo.pyc-2.4.
        base, ext = os.path.splitext(f)
        if not ext or ext.startswith('.py'):
          files.append(base)
    except EnvironmentError:
      pass

    # Get new-style path hook object for this dir
    loader = None
    for path_hook in path_hooks:
      try:
        loader = path_hook(dirname)
        break  # Success if got this far
      except ImportError:
        pass

    path_data.append([dirname, files, loader])

  return path_data


def _FindInPath(module_name, path_data):
  """Heuristic search for a module in a set of directories.

  module_name: top-level module name.  E.g. 'MySQLdb'
  path_data: List of (path, [dir contents if real dir], loader if zipfile)

  Returns the filename to the module or package dir, or None if not found.
  """
  assert '.' not in module_name, 'Contact build-help@google.com'

  for path, files, loader in path_data:
    if module_name in files:
      # Look for __init__.py.  We delay this check until here to avoid
      # I/O in the common case.
      package_fn = os.path.join(path, module_name)
      init_fn = os.path.join(package_fn, '__init__.py')
      if os.path.exists(init_fn):
        return package_fn

    if loader and loader.find_module(module_name):
      return os.path.join(path, module_name)

  return None


########################################################################
# Support for Google extension modules.
########################################################################

def _ImportSimpleDL():
  # We use 'simpledl', as 'dl' is not 64-bit compatible.
  # In effect:
  #   from google3.tools import _tools_simpledl as dl
  # but we don't use "import" as we want to slip under the radar of
  # autopar's dependency analysis---otherwise all google3 code would
  # appear to depend on "tools".

  return __import__('google3.tools', globals(), None,
                    ['_tools_simpledl'])._tools_simpledl

def _PreloadBuggyModules():
  """Preload dynamic modules which would otherwise pollute the run-time
     linker's symbol space"""

  # This code contains nasty hacks. Viewer discretion is advised.

  # We have a problem with two modules in GRTE: _ssl.so and _hashlibmodule.so.
  # These modules have been 'sort of' statically linked with OpenSSL. However,
  # they are exporting their OpenSSL symbols into the dynamic symbol space and
  # their references to OpenSSL functions go via the PLT.

  # google3 also has OpenSSL and we don't maintain binary ABI compatibility
  # over time. So, if a Python program run-time links google3's OpenSSL,
  # it'll populate the dynamic symbol space. Later, if it imports hashlib then
  # it'll get GRTE's hashlib which will end up calling google3's OpenSSL
  # functions. This will, at best, crash and possibly just cause subtle memory
  # corruption.

  # The reverse doesn't happen. When Python imports a shared library it does so
  # with RTLD_NOW (and RTLD_LAZY is the default). As this doesn't include
  # RTLD_GLOBAL, GRTE's symbols don't enter the dynamic symbol space.

  # We can't tell if a google3 Python program is going to pull in OpenSSL. It
  # can happen via SWIG, or via third_party/py/hashlib or via any extension
  # module that someone may write. So we cause the run-time linker to load
  # these libraries now. We tell it to resolve everything and not to include
  # them in the dynamic symbol space. This will cause the their PLT entries to
  # be resolved against their own symbols because we are assuming that
  # google3's OpenSSL hasn't been linked in yet. It also means that, should
  # they later be imported, the run-time linker will just return a reference to
  # the instance that we're loading now and their symbols won't escape.

  # As mentioned above, if GRTE's modules are imported first there's no problem
  # because they'll have been RTLD_NOW linked against themselves.

  # We could just use Python's import statement to do this. However, if we do
  # that, then any google3 modules meant to replace the _ssl or _hashlib
  # modules will import the wrong extension module. Both ssl and hashlib import
  # an extension module (_ssl and _hashlib). If we have already imported them
  # then that'll be the entry in the modules dictionary for that name.

  # This hack only applies to GRTE:
  if sys.platform in ['win32', 'darwin']:
    return

  if not sys.prefix.startswith('/usr/grte/'):
    # This doesn't appear to be a GRTE python
    return

  try:
    dl = _ImportSimpleDL()
  except:
    # This can occur when using an embedded Python interpreter. The dependency
    # on simpledl is inserted by Blaze automatically for targets of type
    # py_binary or py_test so it's possible that simpledl isn't included in the
    # runfiles. Even if it is included in the runfiles, due to conflicting
    # requirements, Blaze can end up building it in the host configuration
    # (often via tinypar) and we can't import it because of an ABI mismatch.
    #
    # Still further, even if we can import simpledl in the case of an embedded
    # interpreter, it's very likely that google3 OpenSSL is already linked into
    # that binary at this point and so preloading doesn't help because the
    # modules will still bind to the google3 symbols.
    #
    # All teams using an embedded interpreter for non-trival cases were emailed
    # on 18/02/2011 about this issue.
    return

  version = sys.version_info[:2]
  dyndir = os.path.join(sys.prefix, 'lib', 'python%d.%d' % version,
                        'lib-dynload')
  modules = [os.path.join(dyndir, '_ssl.so')]
  if version > (2, 4):
    modules.append(os.path.join(dyndir, '_hashlibmodule.so'))

  for m in modules:
    try:
      dl.open(m, dl.RTLD_NOW|dl.RTLD_LOCAL)
    except:
      pass


def _SetupSwig():
  """Setup environment for Blaze built extension modules."""

  # google3 C++ binaries do not work on Windows or Macintosh. Avoid the
  # extra work by returning early.
  if sys.platform in ['win32', 'darwin']:
    return

  # Check for the special module provided by Hermetic Python. Don't try
  # importing it, so we don't pick up a different module if we're not using
  # Hermetic Python.
  launcher_info = sys.modules.get('_launcher_info')
  if launcher_info is not None and launcher_info.is_google3_python_launcher:
    return  # Hermetic Python links all native deps in.  There is no DSO.

  # If we are running a program that uses SWIG, a special library
  # called "pkg/rule_swigdeps.so" will have been created.  Its only
  # purpose is to include functionality indirectly needed by SWIG
  # modules. E.g. pywrapfile.so indirectly relies on code in
  # util/hash/hash.cc, so we put util/hash/hash.o into swigdeps.so.
  # We can't always use the exact name "swigdeps.so", in particular
  # when using multiple combinations of extension modules from the
  # same runfiles directory, which is convenient to do for, for
  # example, py_tests. The GOOGLE3_NATIVE_CODE_DEPS_DSO environment
  # variable, if set, should be set to the absolute path of the
  # filename to dlopen.  (Note that the .par header and py_binary stub
  # script contain relative paths for this variable, but they
  # resolve it to an absolute path at runtime.)
  #
  # This variable is an implementation detail of google3 Python.  It
  # is not a published interface.  DO NOT USE IT IN YOUR SCRIPTS.  If
  # you're tempted to do so, build-help@google.com can talk you out
  # of it.
  #
  # We intentionally let subprocesses inherit the value of
  # GOOGLE3_NATIVE_CODE_DEPS_DSO.  There are several cases to consider here:
  #
  # 1. Some py_binaries re-execute themselves via os.system(sys.argv) to achieve
  #    multiprocess concurrency (less buggy than fork). This does not go through
  #    the py_binary stub script which sets up GOOGLE3_NATIVE_CODE_DEPS_DSO, so
  #    to support this operation, we must leave the environment variable set so
  #    that the child will load its native code.
  #
  # 2. Subprocesses that are py_binaries invoked via their stub or .par and
  #    which use native code: these will override GOOGLE3_NATIVE_CODE_DEPS_DSO
  #    with their own value in the stub code, so leaving it set is harmless to
  #    them.
  #
  # 3. Subprocesses that are py_binaries invoked via their stub or .par and
  #    which do *not* use native code.  Their stubs explicitly clear
  #    GOOGLE3_NATIVE_CODE_DEPS_DSO, so leaving it set is harmless to them as
  #    well.
  #
  # 4. Subprocesses that are Python scripts invoked by direct execution of their
  #    .py file, which need to use the same swigdep DSOs as this process. This
  #    use case is deprecated; it is mostly used these days in GSA (enterprise)
  #    code.  New code should always execute the .par or stub (except for the
  #    special case of (1) above).  This very special case does still work,
  #    though, for the same reason that (1) does: we left
  #    GOOGLE3_NATIVE_CODE_DEPS_DSO alone and there's no stub/.par to set or
  #    clear it, so __init__.py finds the same DSOs in the subprocess as in the
  #    parent process.
  #
  # 5. Subprocesses that are Python scripts invoked by direct execution of their
  #    .py file, which need to use *different* swigdep DSOs as this
  #    process. This never worked correctly (since there was nothing to tell the
  #    subprocess where to find the right DSOs), so we don't care if it
  #    continues to work or not.
  #
  # 6. Subprocesses that are Python scripts invoked by direct execution of their
  #    .py file, which don't need to use swigdep DSOs at all.  This is
  #    deprecated like case (4) (but unlike case (5) needs to be supported).
  #    Because we're leaving GOOGLE3_NATIVE_CODE_DEPS_DSO set (see cases (1) and
  #    (4)) and there's no stub/.par to clear it, the subprocess will try to
  #    dlopen the GOOGLE3_NATIVE_CODE_DEPS_DSO file, even though it won't later
  #    use it.  This may seem harmless, but there's one problem: what if
  #    GOOGLE3_NATIVE_CODE_DEPS_DSO no longer resolves to a loadable file?  For
  #    example, what if it is a relative path and the parent process chdir'd
  #    before running the subprocess?  In this case, we want the subprocess to
  #    ignore whatever error dlopen throws.
  #
  # So should we ignore errors for dlopen?  In case (6) we have to.  But we
  # don't want to always ignore dlopen errors: it would be nice to get the error
  # for a py_binary executed properly via stub/.par, at the very least!  We
  # solve this with a bit of a hack: we have a second environment variable,
  # GOOGLE3_NATIVE_CODE_DEPS_NEEDED, which is set in the stub/.par and cleared
  # after dlopen.  If this variable is not set, we suppress errors.  This means
  # that we see dlopen errors in any process executed via stub/.par, and
  # suppress errors in processes invoked by direct execution of .py files.
  # (This assumes that the process imports some google3 code before executing
  # the subprocess.)
  native_code_deps_dso = os.environ.get('GOOGLE3_NATIVE_CODE_DEPS_DSO')
  native_code_deps_needed = os.environ.get('GOOGLE3_NATIVE_CODE_DEPS_NEEDED')

  # If native_code_deps_dso is included in LD_PRELOAD, it's set by
  # Blaze/tinypar, or explicitly set by the user (using for example
  # PAR_LD_PRELOAD.) In either case we need to remove it (in order not to
  # interfere with new processes that use different swigdeps, or none at
  # all.) If calling code needs it to not be unset, it can either unset
  # GOOGLE3_NATIVE_CODE_DEPS_DSO or use a different path to the same file.
  ld_preload = os.environ.get('LD_PRELOAD')
  if native_code_deps_dso and ld_preload:
    parts = ld_preload.split()
    other_parts = [part for part in parts if part != native_code_deps_dso]
    if parts and not other_parts:
      # The only entry in LD_PRELOAD was native_code_deps_dso. Remove it
      # entirely and don't bother calling dlopen() on native_code_deps_dso
      # -- it should already be loaded.
      del os.environ['LD_PRELOAD']
      return
    elif len(other_parts) != len(parts):
      # LD_PRELOAD contained native_code_deps_dso, but it wasn't the only
      # thing on there.  Reassemble LD_PRELOAD without native_code_deps_dso,
      # and then like above skip calling dlopen().
      os.environ['LD_PRELOAD'] = ' '.join(other_parts)
      return
  if native_code_deps_dso:
    try:
      dl = _ImportSimpleDL()
    except AttributeError:  # (no such attribute '_tools_simpledl')
      # Quietly ignore loading failures unless GOOGLE3_NATIVE_CODE_DEPS_NEEDED
      # is set.  See //tools/internal:python_startup_regtest and bug #1506880.
      if native_code_deps_needed:
        raise
      return
    try:
      dl.open(native_code_deps_dso, dl.RTLD_NOW|dl.RTLD_GLOBAL)
    except OSError:
      if native_code_deps_needed:
        raise
      # Otherwise quietly ignore loading failures; see above.
    del dl
    if native_code_deps_needed:
      del os.environ['GOOGLE3_NATIVE_CODE_DEPS_NEEDED']


########################################################################
# Code run at import time
########################################################################

# Issue a warning for unsupported Python versions.
if sys.version_info[:2] not in ((2, 6), (2, 7)):
  _msg = 'Python %d.%d is unsupported; use 2.7' % sys.version_info[:2]
  warnings.warn(_msg, DeprecationWarning, stacklevel=1)

# The google3 directory; for people who need to orient themselves.
basedir = os.path.dirname(os.path.abspath(__file__))

# Private variables used by meta import hook
_g_inherit_path__ = 1
_g_inherit_processed__ = 1

# Code executed at import time for all Google3 programs.
__path__ = globals().get('__path__', [])  # For pychecker
__path__, _google3_path, _have_readonly_dir = _SetupPath(__path__, basedir)
_SetupMergeImportsHook(_have_readonly_dir)
_SetupThirdParty(sys.path, _google3_path)
_PreloadBuggyModules()
_SetupSwig()
